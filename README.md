# Vignette: Evaluating Social Biases in Vision-Language Models

Vignette is a large-scale, structured benchmark designed to diagnose and analyze social biases in Vision-Language Models (VLMs) across multiple dimensions including race, gender, religion, age, nationality, and more. The benchmark leverages synthetic images and targeted prompt sets to evaluate bias across **factuality**, **perception**, **stereotyping**, and **decision-making** tasks.

While recent VLMs demonstrate impressive multimodal capabilities, they often encode implicit and explicit social biases. Vignette offers a cognitively grounded, socially informed evaluation framework to assess these models using controlled, synthetic image-text pairs.

## 📦 Features

- 75 real-world inspired **activities**
- 160+ unique **social identities**
- 60+ **descriptive traits**
- 4 evaluation paradigms:
  - **Factuality**: Is the output factually accurate?
  - **Perception**: How does the model perceive people?
  - **Stereotyping**: Does it reproduce societal stereotypes?
  - **Decision Making**: What decisions does it make about people?

## 📁 Repo Structure

```bash
.
├── data/ # Contains data files used in the project
├── figures/ # Includes generated figures and visualizations
├── more_figures/ # Additional figures and related resources
├── outputs/ # Output files (e.g., results from models)
├── src/ # Source code for the project
├── .gitignore # Specifies files and directories to be ignored by Git
└── README.md # Project documentation (this file)
```
## 📂 Output Access

The full set of generated outputs (~36GB), and synthetic images (30M+) will be made available separately:

[Download Outputs (Public Link)](https://your-link-here.com)

[Download Images (Public Link)](https://your-link-here.com)

**Note:** Due to anonymity policies related to ongoing submissions, the public download link will be made available at a later stage.