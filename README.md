# Vignette: Evaluating Social Biases in Vision-Language Models

Vignette is a large-scale, structured benchmark designed to diagnose and analyze social biases in Vision-Language Models (VLMs) across multiple dimensions including race, gender, religion, age, nationality, and more. The benchmark leverages synthetic images and targeted prompt sets to evaluate bias across **factuality**, **perception**, **stereotyping**, and **decision-making** tasks.

While recent VLMs demonstrate impressive multimodal capabilities, they often encode implicit and explicit social biases. Vignette offers a cognitively grounded, socially informed evaluation framework to assess these models using controlled, synthetic image-text pairs.

## ğŸ“¦ Features

- 75 real-world inspired **activities**
- 160+ unique **social identities**
- 60+ **descriptive traits**
- 4 evaluation paradigms:
  - **Factuality**: Is the output factually accurate?
  - **Perception**: How does the model perceive people?
  - **Stereotyping**: Does it reproduce societal stereotypes?
  - **Decision Making**: What decisions does it make about people?

## ğŸ“ Repo Structure

```bash
.
â”œâ”€â”€ data/
â”œâ”€â”€ figures/
â”œâ”€â”€ src/
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
## ğŸ“‚ Output Access

The full set of generated outputs (~36GB), and synthetic images (30M+) will be made available separately:

[Download Outputs (Public Link)](https://your-link-here.com)

[Download Images (Public Link)](https://your-link-here.com)

**Note:** Due to anonymity policies related to ongoing submissions, the public download link will be made available at a later stage.